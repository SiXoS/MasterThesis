\chapter{Introduction}

\section{Aim and background}
The neighborhood function (NF) is used for determining node reachability in graphs. For each node in a graph the NF calculates how many other nodes it can reach in a limited number of steps. Formally speaking, given a graph $G = (V,E)$ NF calculates $\forall u \in V,$ $N(u,h) = |\{v : v \in V, dist(u,v) \leq h \}|$ where $h$ is the maximum number of steps. Due to the dependence on the value $h$, a variety of graph properties can be expressed by the NF. For example, the diameter of a graph can be expressed as the smallest number $d$ where $ \forall u \in V$, $N(u,d) = N(u,\infty)$. By setting h to a fixed value $h < d$ we can calculate the fraction of the graph that a node can reach in h steps. 

The neighborhood function can be calculated exactly in either $O(n^{2.38})$ operations and $O(n^2)$ space units or $O(nm)$ operations and $O(m + n)$ space units, where $n$ is the number of nodes and $m$ is the number of edges \cite{Palmer01}. However, for very large graphs even these polynomial bounds become infeasible. Therefore, there has been a great deal of recent research concerning the development of approximation algorithms to calculate the neighborhood function \cite{Palmer01,anf,hyperanf}. 

HyperANF is a state-of-the-art algorithm, created by P.Boldi et al, that provides an approximation for the neighborhood function \cite{hyperanf}. HyperANF uses HyperLogLog counters to approximate the number of nodes a given node can reach. HyperLogLog counters are statistical counters that require only $O( \log\log (n))$ bits to approximate the cardinality of a set up to size $n$ \cite{hyperloglog}. In HyperANF each node is given a constant number of counters, and hence requires $O(n \log\log(n))$ space. However, HyperANF doesn't have any stated time complexity, but it is at least as good as ANF, which runs in $O((n+m)h)$, where h is the number of steps. The authors provide benchmarks on public data-sets that empirically show that it is much faster that its predecessors, including ANF. Due to the HyperANFs low space complexity, it works well on graphs with number of edges at the scale of billions. Currently the algorithm supports only static graphs. This paper aims to extend the existing algorithm to support dynamic graphs.

NF for dynamic graphs can be an efficient tool to gather information from very large graphs continuously and see changes in influence over time. This has plenty of applications in the real world. For example, think of a graph of companies with some relations (for example if they collaborate on projects projects). Assume that this graph is being updated in real time. The NF can be used to calculate which companies are most influential at the moment. But even more interesting would be to see how the graph evolve over time. This can give insight into which companies that are gaining more and more influence. A stock trader might have a huge advantage in seeing this information. The NF can be used repeatedly to monitor changes as well, but depending on how large the graph is it can take hours to recalculate. The stock market might have already closed for the day after the recalculation is finished. Instead, a dynamic NF can provide a continuously updated graph throughout the day. The trader can then get updates anytime throughout the day without any delay.

\section{Problem formulation}
The formalized problem is as follows: 
Let $G_i$ be the graph $G_i = (V_i,E_i)$ at time $i = 1,2,3,...$.
Let $A_i$ be the set of added nodes in $G_i$ and $D_i$ the set of deleted nodes. 
At each time step $i > 1$ we have  $G_i = (G_{i-1} \backslash D_{i-1}) \cup A_{i-1}$ and $G_1$ is the original graph. Given the neighborhood function $N(u, h) = |\{v : v \in V, dist(u,v) \leq h \}|$ for all $u \in V$ in $G_1$, we wish to continuously update the neighborhood function for $G_{i>1}$ without performing a complete recalculation of $N(u, h)$ $\forall u \in V_i$. Additionally, we have the criteria that our solution should work for very large graphs, hence the solution must be scalable. 

The algorithm will be used by Meltwater to define an influence metric on journalists. A graph will initially be built from the data collected by Meltwater. The data comes from sources such as news papers and social networks. Whenever more information is collected the graph should be updated to continuously contain relevant information. The number of new documents each day is in the scale of tens of millions and the existing documents are in the scale of billions. To be able to handle these magnitudes, the time and space complexity of our proposed algorithm are very limited.

\section{Limitations}
\subsection{Entity disambiguating}
A problem that occurs when constructing graphs is how to disambiguate the nodes. How are we to know when two entities are the same? Say, we have a graph consisting of a nodes which represents individual identities. Suppose that there exists a node with the label Anders Svensson. Next we want to add an article regarding a person with similar name. Does this article concern the already existing Anders, or should we create a new node to distinguish between them? Disambiguating entities is important in the construction of the graph, as we are likely to get false results from the graph searches otherwise. Meltwater has an NLP-department which already disambiguates entities with a good performance. Therefore, we assume that the entity disambiguation, already in place by Meltwater, is flawless. 