\chapter{Methods}

\todo{What tempus should this be in? Past or future?}

A lot of work on large graphs and the approximate neighborhood function has been done by P. Boldi et. al. with the webgraph framework\cite{webgraph}. The framework will be studied extensively to understand the methods used. As the framework only support static graphs, extensions to the framework will be made to support dynamic graphs and an evolving approximate neighborhood function. 

The research will be mainly about the compression techniques of webgraph graphs \cite{webgraph-compression} and the HyperBall algorithm \cite{hyperball}, including HyperLogLog counters \cite{hyperloglog}. Research of dynamic algorithms will also be made.


\section{Merging graphs}
The compression methods used are very sensitive to changes. Nodes can copy neighbors from other nodes so if the neighbors of a node change all nodes that reference the modified node have to be found and updated as well. Moreover, the graph is either stored in a file or in a byte buffer. None of these support insertion of data at an arbitrary position without expensive reallocation and repositioning of the data succeeding that position. 

As dynamic graphs are required, the optimal method of merging two graphs should be investigated. This may include ignoring some compression methods if it speeds up the merge significantly.


\section{Extending HyperANF to support dynamic graphs}
The proposed algorithm should include two phases. In the first phase, the proposed algorithm shall run HyperANF on the current state of the graph. The second phase is the dynamic part, which starts immediately after HyperANF has completed its calculations.  In the second phase the algorithm should take the information produced by HyperANF and modify it when new nodes and edges are added or deleted. The algorithm can either make the appropriate changes for every node added and deleted, or buffer up a sub-graph, run an algorithm on this sub-graph, and then merge it with the larger graph. The second approach will be faster as nodes can share results. However, it is not certain that the second approach will be as precise as the first approach. 

To update the neighborhood function, approaches to update nodes in the graph efficiently must be studied. The main problem will be to find which nodes are affected by a change somewhere in the graph.


\section{Extending HyperLogLog to support deletions}
As nodes in the graph can be deleted, there has to be a way to remove elements from the HyperLogLog counters.  A way to delete an element from the counter while preserving the accuracy should be proposed. If there is no time to accomplish this or the results are not sufficiently accurate, removals could be forbidden. This seems like a drastic choice to make, but many data-streams are of the type "append-only", in which the resulting graph only admits node and edge additions.

To be able to manipulate the HyperLogLog counters in a way that they preserves the current precision, the current implementation must be investigated to give an understanding of how additions are currently performed. This gives insight into how to efficiently decrease the counters without altering their accuracy.


\section{Tracking changes over time}
The proposed algorithm should be able to track changes over time. The node counters must be saved, so that changes can be analysed over time. This may not fit in the memory of a computer. Then, effective ways of storage has to be investigated.


\section{Benchmarks} 
The proposed algorithm should be compared to the static algorithms of ANF.
A simple way to compare the algorithms is to have the static version perform a complete recalculation whenever the graph changes and compare the time for recalculation with the time it takes to insert into the proposed algorithm. Then,
it can be seen how many updates can be performed in the dynamic ANF in the time it takes for the static ANF to complete. For small data-sets it might also be possible to compare the proposed algorithm to an exact computation. For other researches to be able to compare their algorithm to the proposed algorithm, the data-sets used to perform the benchmarks presented in the final thesis will be publicly available.





