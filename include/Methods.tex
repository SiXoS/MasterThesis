\chapter{Methods}

A lot of work on large graphs and the approximate neighborhood function has been done by P. Boldi et. al. with the webgraph framework\cite{webgraph}. The framework were studied extensively to understand the methods used. As the framework only supported static graphs, extensions to the framework has been made to support dynamic graphs and an evolving approximate neighborhood function. 

The research was mainly focused on compression techniques of webgraph graphs \cite{webgraph-compression} and the HyperBall algorithm \cite{hyperball}, including HyperLogLog counters \cite{hyperloglog}. Extensive research was also made on general dynamic algorithms and tools that are used in our algorithm.


\section{Merging graphs}
The compression methods used are very sensitive to changes. Nodes can copy neighbors from other nodes so if the neighbors of a node change all nodes that reference the modified node have to be found and updated as well. Moreover, the graph is either stored in a file or in a byte buffer. None of these support insertion of data at an arbitrary position without expensive reallocation and repositioning of the data succeeding that position. As dynamic graphs are required, the optimal method of merging two graphs has been investigated. 


\section{Extending HyperANF to support dynamic graphs}
The proposed algorithm has been divided into two phases. In the first phase, the proposed algorithm runs HyperANF on the intitial state of the graph. The second phase is the dynamic part, which starts immediately after HyperANF has completed its calculations. In the second phase the algorithm takes the information produced by HyperANF and modifies it when new nodes and edges are added or deleted. The algorithm was optimized to handle several changed edges in a bulk to be able to share computations.

To update the neighborhood function, approaches to update nodes in the graph efficiently must be studied. The main problem will be to find which nodes are affected by a change somewhere in the graph.


\section{Extending HyperLogLog to support deletions}
As nodes and edges in the graph should be able to be deleted, there has to be a way to remove elements from the HyperLogLog counters. Extensive research was made to develop a method of deleting elements from a HyperLogLog counter. However, the analysis that would be required to make deletions possible while remaining the precision of the counter was deemed out of the scope. This seems like a drastic choice to make, but many data-streams are of the type "append-only", in which the resulting graph only allows node and edge additions.

An alternative way of supporting deletions was investigated but not implemented due to limited time. The method is mentioned in future work in \ref{sec:future_work}.


\section{Tracking changes over time}
The proposed algorithm should be able to track changes over time. The node counters must be saved, so that changes can be analysed over time. This may not fit in the memory of a computer. Then, effective ways of storage has to be investigated.


\section{Benchmarks} 
The proposed algorithm should be compared to the static algorithms of ANF.
A simple way to compare the algorithms is to have the static version perform a complete recalculation whenever the graph changes and compare the time for recalculation with the time it takes to insert into the proposed algorithm. Then,
it can be seen how many updates can be performed in the dynamic ANF in the time it takes for the static ANF to complete. For small data-sets it might also be possible to compare the proposed algorithm to an exact computation. For other researches to be able to compare their algorithm to the proposed algorithm, the data-sets used to perform the benchmarks presented in the final thesis will be publicly available.





